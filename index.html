<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Voice Synthesizer</title>
    <style>
        body {
            font-family: 'Roboto', sans-serif;
            display: flex;
            flex-direction: column;
            align-items: center;
            justify-content: center;
            height: 100vh;
            background-color: #121212;
            color: #ffffff;
            margin: 0;
        }
        h1 {
            margin-bottom: 20px;
            font-size: 2.5em;
            text-align: center;
        }
        .button {
            margin: 10px 0;
            background-color: #1e1e1e;
            color: #ffffff;
            border: none;
            padding: 10px 20px;
            cursor: pointer;
            border-radius: 5px;
            font-size: 1.1em;
            transition: background-color 0.3s ease;
        }
        .button:hover {
            background-color: #333333;
        }
        .file-input {
            margin: 10px 0;
            background-color: #1e1e1e;
            color: #ffffff;
            border: none;
            padding: 10px 20px;
            cursor: pointer;
            border-radius: 5px;
            font-size: 1.1em;
            transition: background-color 0.3s ease;
        }
        .file-input:hover {
            background-color: #333333;
        }
        #downloadButton {
            display: none;
            background-color: #1e1e1e;
            color: #ffffff;
            border: none;
            padding: 10px 20px;
            cursor: pointer;
            border-radius: 5px;
            font-size: 1.1em;
            text-decoration: none;
            transition: background-color 0.3s ease;
        }
        #downloadButton:hover {
            background-color: #333333;
        }
        audio {
            margin-top: 20px;
            width: 100%;
            max-width: 300px;
        }
    </style>
</head>
<body>
    <h1>Voice Synthesizer</h1>
    <button class="button" id="startRecording">Start Recording</button>
    <button class="button" id="stopRecording">Stop Recording</button>
    <input type="file" id="audioInput" accept="audio/*" class="file-input">
    <button class="button" id="synthesizeVoice">Synthesize Voice</button>
    <audio id="recordedAudio" controls></audio>
    <a id="downloadButton" href="#" download="synthesized_audio.wav" class="button">Download Synthesized Audio</a>
    <script>
        let mediaRecorder;
        let audioChunks = [];
        let audioBlob;
        let uploadedAudioBlob;

        document.getElementById('startRecording').addEventListener('click', startRecording);
        document.getElementById('stopRecording').addEventListener('click', stopRecording);
        document.getElementById('synthesizeVoice').addEventListener('click', synthesizeVoice);

        function startRecording() {
            navigator.mediaDevices.getUserMedia({ audio: true })
                .then(stream => {
                    mediaRecorder = new MediaRecorder(stream);
                    mediaRecorder.start();

                    mediaRecorder.ondataavailable = event => {
                        audioChunks.push(event.data);
                    };

                    mediaRecorder.onstop = () => {
                        audioBlob = new Blob(audioChunks, { type: 'audio/wav' });
                        audioChunks = [];

                        const recordedAudioElement = document.getElementById('recordedAudio');
                        const audioURL = URL.createObjectURL(audioBlob);
                        recordedAudioElement.src = audioURL;
                    };
                })
                .catch(error => console.error('Error accessing microphone:', error));
        }

        function stopRecording() {
            if (mediaRecorder) {
                mediaRecorder.stop();
            }
        }

        async function synthesizeVoice() {
            const fileInput = document.getElementById('audioInput');
            if (fileInput.files.length > 0) {
                const file = fileInput.files[0];
                uploadedAudioBlob = file;
                processAudio(uploadedAudioBlob);
            } else if (audioBlob) {
                processAudio(audioBlob);
            } else {
                alert('Please record an audio or upload a file first');
            }
        }

        async function processAudio(audioBlob) {
            const audioContext = new (window.AudioContext || window.webkitAudioContext)();
            const reader = new FileReader();

            reader.onload = async function(event) {
                try {
                    const buffer = await audioContext.decodeAudioData(event.target.result);

                    const utterance = new SpeechSynthesisUtterance("This is a synthesized voice.");
                    utterance.voice = window.speechSynthesis.getVoices()[0];
                    utterance.pitch = 0.1;  // Make the voice deeper

                    // Convert speech synthesis output to audio buffer
                    const synthAudioBuffer = await synthesizeSpeechToBuffer(utterance, audioContext);

                    // Combine original and synthesized audio data
                    const combinedBuffer = audioContext.createBuffer(
                        1,
                        buffer.length + synthAudioBuffer.length,
                        buffer.sampleRate
                    );
                    const combinedData = combinedBuffer.getChannelData(0);
                    combinedData.set(buffer.getChannelData(0), 0);
                    combinedData.set(synthAudioBuffer.getChannelData(0), buffer.length);

                    // Create a new WAV file from the combined buffer
                    const wavBlob = bufferToWaveBlob(combinedBuffer);

                    const synthesizedAudioElement = document.getElementById('recordedAudio');
                    synthesizedAudioElement.src = URL.createObjectURL(wavBlob);

                    const downloadButton = document.getElementById('downloadButton');
                    downloadButton.href = URL.createObjectURL(wavBlob);
                    downloadButton.style.display = 'block';
                } catch (error) {
                    console.error('Error decoding audio data:', error);
                }
            };

            reader.readAsArrayBuffer(audioBlob);
        }

        async function synthesizeSpeechToBuffer(utterance, audioContext) {
            return new Promise((resolve) => {
                const synthSource = audioContext.createBufferSource();
                const synthProcessor = audioContext.createScriptProcessor(4096, 1, 1);
                const synthData = [];
                synthProcessor.onaudioprocess = (event) => {
                    synthData.push(...event.inputBuffer.getChannelData(0));
                };
                synthProcessor.connect(audioContext.destination);

                utterance.onend = function() {
                    synthProcessor.disconnect();
                    const synthBuffer = audioContext.createBuffer(1, synthData.length, audioContext.sampleRate);
                    synthBuffer.copyToChannel(new Float32Array(synthData), 0);
                    resolve(synthBuffer);
                };
                window.speechSynthesis.speak(utterance);
            });
        }

        function bufferToWaveBlob(buffer) {
            const numOfChan = buffer.numberOfChannels,
                length = buffer.length * numOfChan * 2 + 44,
                bufferArray = new ArrayBuffer(length),
                view = new DataView(bufferArray),
                channels = [],
                i,
                sample,
                offset = 0,
                pos = 0;

            setUint32(0x46464952); // "RIFF"
            setUint32(length - 8); // file length - 8
            setUint32(0x45564157); // "WAVE"

            setUint32(0x20746d66); // "fmt " chunk
            setUint32(16); // length = 16
            setUint16(1); // PCM (uncompressed)
            setUint16(numOfChan);
            setUint32(buffer.sampleRate);
            setUint32(buffer.sampleRate * 2 * numOfChan);
            setUint16(numOfChan * 2);
            setUint16(16); // bits per sample

            setUint32(0x61746164); // "data" - chunk
            setUint32(length - pos - 4); // chunk length

            for (i = 0; i < buffer.numberOfChannels; i++) {
                channels.push(buffer.getChannelData(i));
            }

            while (pos < length) {
                for (i = 0; i < numOfChan; i++) {
                    sample = Math.max(-1, Math.min(1, channels[i][offset])); // clamp
                    sample = (0.5 + sample < 0 ? sample * 32768 : sample * 32767) | 0; // scale to 16-bit signed int
                    view.setInt16(pos, sample, true); // write 16-bit sample
                    pos += 2;
                }
                offset++; // next source sample
            }

            return new Blob([bufferArray], { type: 'audio/wav' });

            function setUint16(data) {
                view.setUint16(pos, data, true);
                pos += 2;
            }

            function setUint32(data) {
                view.setUint32(pos, data, true);
                pos += 4;
            }
        }
    </script>
</body>
</html>
