<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Voice Synthesizer</title>
    <style>
        body {
            font-family: 'Roboto', sans-serif;
            display: flex;
            flex-direction: column;
            align-items: center;
            justify-content: center;
            height: 100vh;
            background-color: #121212;
            color: #ffffff;
            margin: 0;
        }
        h1 {
            margin-bottom: 20px;
            font-size: 2.5em;
            text-align: center;
        }
        .button {
            margin: 10px 0;
            background-color: #1e1e1e;
            color: #ffffff;
            border: none;
            padding: 10px 20px;
            cursor: pointer;
            border-radius: 5px;
            font-size: 1.1em;
            transition: background-color 0.3s ease;
        }
        .button:hover {
            background-color: #333333;
        }
        .file-input {
            margin: 10px 0;
            background-color: #1e1e1e;
            color: #ffffff;
            border: none;
            padding: 10px 20px;
            cursor: pointer;
            border-radius: 5px;
            font-size: 1.1em;
            transition: background-color 0.3s ease;
        }
        .file-input:hover {
            background-color: #333333;
        }
        #downloadButton {
            display: none;
            background-color: #1e1e1e;
            color: #ffffff;
            border: none;
            padding: 10px 20px;
            cursor: pointer;
            border-radius: 5px;
            font-size: 1.1em;
            text-decoration: none;
            transition: background-color 0.3s ease;
        }
        #downloadButton:hover {
            background-color: #333333;
        }
        audio {
            margin-top: 20px;
            width: 100%;
            max-width: 300px;
        }
    </style>
</head>
<body>
    <h1>Voice Synthesizer</h1>
    <button class="button" onclick="startRecording()">Start Recording</button>
    <button class="button" onclick="stopRecording()">Stop Recording</button>
    <input type="file" id="audioInput" accept="audio/*" class="file-input">
    <button class="button" onclick="synthesizeVoice()">Synthesize Voice</button>
    <audio id="recordedAudio" controls></audio>
    <a id="downloadButton" href="#" download="synthesized_audio.wav" class="button">Download Synthesized Audio</a>
    <script>
        let mediaRecorder;
        let audioChunks = [];
        let audioBlob;
        let uploadedAudioBlob;

        function startRecording() {
            navigator.mediaDevices.getUserMedia({ audio: true })
                .then(stream => {
                    mediaRecorder = new MediaRecorder(stream);
                    mediaRecorder.start();

                    mediaRecorder.ondataavailable = event => {
                        audioChunks.push(event.data);
                    };

                    mediaRecorder.onstop = () => {
                        audioBlob = new Blob(audioChunks, { type: 'audio/wav' });
                        audioChunks = [];

                        const recordedAudioElement = document.getElementById('recordedAudio');
                        const audioURL = URL.createObjectURL(audioBlob);
                        recordedAudioElement.src = audioURL;
                    };
                })
                .catch(error => console.error('Error accessing microphone:', error));
        }

        function stopRecording() {
            if (mediaRecorder) {
                mediaRecorder.stop();
            }
        }

        async function synthesizeVoice() {
            const fileInput = document.getElementById('audioInput');
            if (fileInput.files.length > 0) {
                const file = fileInput.files[0];
                uploadedAudioBlob = file;
                processAudio(uploadedAudioBlob);
            } else if (audioBlob) {
                processAudio(audioBlob);
            } else {
                alert('Please record an audio or upload a file first');
            }
        }

        async function processAudio(audioBlob) {
            const audioContext = new (window.AudioContext || window.webkitAudioContext)();
            const reader = new FileReader();

            reader.onload = async function(event) {
                try {
                    const buffer = await audioContext.decodeAudioData(event.target.result);

                    const utterance = new SpeechSynthesisUtterance("This is a synthesized voice.");
                    utterance.voice = window.speechSynthesis.getVoices()[0];

                    // Convert speech synthesis output to audio buffer
                    const synthAudioBuffer = await synthesizeSpeechToBuffer(utterance, audioContext);

                    // Combine original and synthesized audio data
                    const combinedBuffer = audioContext.createBuffer(
                        1,
                        buffer.length + synthAudioBuffer.length,
                        buffer.sampleRate
                    );
                    const combinedData = combinedBuffer.getChannelData(0);
                    combinedData.set(buffer.getChannelData(0), 0);
                    combinedData.set(synthAudioBuffer.getChannelData(0), buffer.length);

                    // Create a new WAV file from the combined buffer
                    const wavBlob = await bufferToWaveBlob(combinedBuffer, audioContext);

                    const synthesizedAudioElement = document.getElementById('recordedAudio');
                    synthesizedAudioElement.src = URL.createObjectURL(wavBlob);

                    const downloadButton = document.getElementById('downloadButton');
                    downloadButton.href = URL.createObjectURL(wavBlob);
                    downloadButton.style.display = 'block';
                } catch (error) {
                    console.error('Error decoding audio data:', error);
                }
            };

            reader.readAsArrayBuffer(audioBlob);
        }

        async function synthesizeSpeechToBuffer(utterance, audioContext) {
            return new Promise((resolve) => {
                const synthSource = audioContext.createBufferSource();
                const synthProcessor = audioContext.createScriptProcessor(4096, 1, 1);
                const synthData = [];
                synthProcessor.onaudioprocess = (event) => {
                    synthData.push(...event.inputBuffer.getChannelData(0));
                };
                synthProcessor.connect(audioContext.destination);

                utterance.onend = function() {
                    synthProcessor.disconnect();
                    const synthBuffer = audioContext.createBuffer(1, synthData.length, audioContext.sampleRate);
                    synthBuffer.copyToChannel(new Float32Array(synthData), 0);
                    resolve(synthBuffer);
                };
                window.speechSynthesis.speak(utterance);
            });
        }

        async function bufferToWaveBlob(buffer, audioContext) {
            const wavData = audioContext.createWaveFile(buffer, {
                sampleRate: buffer.sampleRate,
                channels: buffer.numberOfChannels,
                bitDepth: 16
            });
            return new Blob([wavData], { type: 'audio/wav' });
        }
    </script>
</body>
</html>
