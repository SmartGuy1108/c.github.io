<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Voice Synthesizer</title>
    <style>
        body {
            font-family: Arial, sans-serif;
            display: flex;
            flex-direction: column;
            align-items: center;
            justify-content: center;
            height: 100vh;
            background-color: #121212;
            color: #ffffff;
        }
        button, input[type="file"], #downloadButton {
            margin: 10px 0;
            background-color: #1e1e1e;
            color: #ffffff;
            border: none;
            padding: 10px 20px;
            cursor: pointer;
        }
        button:hover, input[type="file"]:hover, #downloadButton:hover {
            background-color: #333333;
        }
        #downloadButton {
            display: none;
            text-decoration: none;
        }
    </style>
</head>
<body>
    <h1>Voice Synthesizer</h1>
    <button onclick="startRecording()">Start Recording</button>
    <button onclick="stopRecording()">Stop Recording</button>
    <input type="file" id="audioInput" accept="audio/*">
    <button onclick="synthesizeVoice()">Synthesize Voice</button>
    <br>
    <audio id="recordedAudio" controls></audio>
    <br>
    <a id="downloadButton" href="#" download="synthesized_audio.wav">Download Synthesized Audio</a>
    <script>
        let mediaRecorder;
        let audioChunks = [];
        let audioBlob;
        let uploadedAudioBlob;

        function startRecording() {
            navigator.mediaDevices.getUserMedia({ audio: true })
                .then(stream => {
                    mediaRecorder = new MediaRecorder(stream);
                    mediaRecorder.start();

                    mediaRecorder.ondataavailable = event => {
                        audioChunks.push(event.data);
                    };

                    mediaRecorder.onstop = () => {
                        audioBlob = new Blob(audioChunks, { type: 'audio/wav' });
                        audioChunks = [];

                        const recordedAudioElement = document.getElementById('recordedAudio');
                        const audioURL = URL.createObjectURL(audioBlob);
                        recordedAudioElement.src = audioURL;
                    };
                })
                .catch(error => console.error('Error accessing microphone:', error));
        }

        function stopRecording() {
            if (mediaRecorder) {
                mediaRecorder.stop();
            }
        }

        async function synthesizeVoice() {
            const fileInput = document.getElementById('audioInput');
            if (fileInput.files.length > 0) {
                const file = fileInput.files[0];
                uploadedAudioBlob = file;
                processAudio(uploadedAudioBlob);
            } else if (audioBlob) {
                processAudio(audioBlob);
            } else {
                alert('Please record an audio or upload a file first');
            }
        }

        async function processAudio(audioBlob) {
            const audioContext = new (window.AudioContext || window.webkitAudioContext)();
            const reader = new FileReader();

            reader.onload = async function(event) {
                try {
                    const buffer = await audioContext.decodeAudioData(event.target.result);
                    const source = audioContext.createBufferSource();
                    source.buffer = buffer;
                    source.connect(audioContext.destination);
                    source.start(0);

                    const utterance = new SpeechSynthesisUtterance("This is a synthesized voice.");
                    utterance.voice = window.speechSynthesis.getVoices()[0];
                    
                    // Convert speech synthesis output to audio buffer
                    const synthAudioBuffer = await new Promise((resolve) => {
                        utterance.onend = function() {
                            const synthSource = audioContext.createBufferSource();
                            synthSource.buffer = buffer;
                            synthSource.connect(audioContext.destination);
                            synthSource.start(0);
                            resolve(synthSource.buffer);
                        };
                        window.speechSynthesis.speak(utterance);
                    });

                    // Combine original and synthesized audio
                    const combinedBuffer = audioContext.createBuffer(
                        1,
                        buffer.length + synthAudioBuffer.length,
                        buffer.sampleRate
                    );
                    const combinedData = combinedBuffer.getChannelData(0);
                    combinedData.set(buffer.getChannelData(0), 0);
                    combinedData.set(synthAudioBuffer.getChannelData(0), buffer.length);

                    const synthesizedBlob = new Blob([combinedBuffer.getChannelData(0)], { type: 'audio/wav' });

                    const synthesizedAudioElement = document.getElementById('recordedAudio');
                    synthesizedAudioElement.src = URL.createObjectURL(synthesizedBlob);

                    const downloadButton = document.getElementById('downloadButton');
                    downloadButton.href = URL.createObjectURL(synthesizedBlob);
                    downloadButton.style.display = 'block';
                } catch (error) {
                    console.error('Error decoding audio data:', error);
                }
            };

            reader.readAsArrayBuffer(audioBlob);
        }
    </script>
</body>
</html>
